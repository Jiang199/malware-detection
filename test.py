import numpy as np
import pandas as pd
from keras.models import Sequential
from keras.layers import Dense, Activation, Flatten, Conv1D, MaxPooling1D, GlobalAveragePooling1D, Dropout, Embedding


def get_empty_model(params):
    print(params)
    conv_dropout_1 = params['conv_dropout_1']
    conv_dropout_2 = params['conv_dropout_2']
    conv_dropout_3 = params['conv_dropout_3']
    conv_dropout_4 = params['conv_dropout_4']
    conv_dropout_5 = params['conv_dropout_5']
    dense_dropout = params['dense_dropout']
    dense_dim = params['dense_dim']
    optimizer = params['optimizer']
    batch_size = params['batch_size']
    epochs = params['epochs']

    input_length = 4096

    model = Sequential()
    model.add(Embedding(256, 16, input_length=input_length))
    model.add(Dropout(conv_dropout_1))
    model.add(Conv1D(48, 32, strides=4, padding='same', dilation_rate=1, activation='relu', use_bias=True,
                     kernel_initializer='glorot_uniform', bias_initializer='zeros'))
    model.add(Dropout(conv_dropout_2))
    model.add(Conv1D(96, 32, strides=4, padding='same', dilation_rate=1, activation='relu', use_bias=True,
                     kernel_initializer='glorot_uniform', bias_initializer='zeros'))
    model.add(Dropout(conv_dropout_3))
    model.add(MaxPooling1D(pool_size=4, strides=None, padding='valid'))
    model.add(Conv1D(128, 16, strides=8, padding='same', dilation_rate=1, activation='relu', use_bias=True,
                     kernel_initializer='glorot_uniform', bias_initializer='zeros'))
    model.add(Dropout(conv_dropout_4))
    model.add(Conv1D(192, 16, strides=8, padding='same', dilation_rate=1, activation='relu', use_bias=True,
                     kernel_initializer='glorot_uniform', bias_initializer='zeros'))
    model.add(Dropout(conv_dropout_5))

    model.add(Flatten())

    model.add(Dense(dense_dim, activation='selu'))
    model.add(Dropout(dense_dropout))

    model.add(Dense(1, activation='sigmoid'))
    model.compile(optimizer=optimizer,
                  loss='binary_crossentropy',
                  metrics=['accuracy'])

    return model


if __name__ == "__main__":
    params = {
        'batch_size': 128,
        'conv_dropout_1': 0.2,
        'conv_dropout_2': 0.2,
        'conv_dropout_3': 0.2,
        'conv_dropout_4': 0.2,
        'conv_dropout_5': 0.2,
        'dense_dim': 64,
        'dense_dropout': 0.5,
        'epochs': 40,
        'optimizer': 'adam'
    }

    test = pd.read_csv(r'test.csv', header=None, names=list(range(4096)), usecols=list(range(4096)),
                       dtype=np.float16)
    test.fillna(0, inplace=True)
    test = test.astype(np.int16)

    # Load trained models from hdf5 files, and ensemble results by
    # Taking mean of the predictions of 3 models.
    final_model_1 = get_empty_model(params)
    final_model_1.load_weights('model_1-49-0.9795.hdf5')
    X_test = test.values
    pred = final_model_1.predict(X_test)
    result_array_1 = pred.flatten()

    final_model_2 = get_empty_model(params)
    final_model_2.load_weights('model_2-13-0.9792.hdf5')
    X_test = test.values
    pred = final_model_2.predict(X_test)
    result_array_2 = pred.flatten()

    final_model_3 = get_empty_model(params)
    final_model_3.load_weights('model_3-30-0.9789.hdf5')
    X_test = test.values
    pred = final_model_3.predict(X_test)
    result_array_3 = pred.flatten()

    result_array = (result_array_1 + result_array_2 + result_array_3) / 3

    sample_id = range(pred.shape[0])
    df_pred = pd.DataFrame(
        {'sample_id': sample_id,
         'malware': result_array
         })
    df_pred.to_csv('result.csv', columns=['sample_id', 'malware'], index=False)
